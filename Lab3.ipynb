{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0185ba0-5c67-447a-bc19-13ce0acbf705",
   "metadata": {},
   "source": [
    "Побудувати CNN на основі ResNet-50 для класифікації зображень на основі\n",
    "датасету fashion-mnist.\n",
    "Зробити налаштування моделі для досягнення необхідної точності. На базі\n",
    "Siamese networks побудувати систему для пошуку подібних зображень в\n",
    "датасеті fashion-mnist. Візуалізувати отримані результати t-SNE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8c561368-a304-4197-bbf8-61af4ce24c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "#from keras.models import Model\n",
    "#from keras.layers import Input, Conv2D, BatchNormalization, MaxPool2D, Activation, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, ZeroPadding1D, Flatten, BatchNormalization, AveragePooling1D, Dense, Activation, Add \n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import activations\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "66a75259-eb43-455a-b204-104ed02e2fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, Y_train), (X_test, Y_test) = tf.keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f6ef2a61-d1dc-4bcc-8548-f42a8897584e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9d02c1e6-bc17-4794-9ec7-aead7e5233e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_shape =  np.concatenate((X_test.shape[1:], [1]))\n",
    "CLASSES = len(np.unique(Y_test))\n",
    "EPOCH=17\n",
    "BS = 128\n",
    "\n",
    "train_images = X_train / 255.0\n",
    "test_images = X_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c1246108-7fba-45b6-a282-5a7d9cb72510",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def create_pairs(x, digit_indices):\n",
    "    '''\n",
    "    Positive and negative pair creation.\n",
    "    Alternates between positive and negative pairs.\n",
    "    '''\n",
    "    pairs = []\n",
    "    labels = []\n",
    "    n = min([len(digit_indices[d]) for d in range(CLASSES)]) - 1\n",
    "    for d in range(CLASSES):\n",
    "        for i in range(n):\n",
    "            z1, z2 = digit_indices[d][i], digit_indices[d][i + 1]\n",
    "            pairs += [[x[z1], x[z2]]]\n",
    "            inc = random.randrange(1, CLASSES)\n",
    "            dn = (d + inc) % CLASSES\n",
    "            z1, z2 = digit_indices[d][i], digit_indices[dn][i]\n",
    "            pairs += [[x[z1], x[z2]]]\n",
    "            labels += [1, 0]\n",
    "    return np.array(pairs), np.array(labels)\n",
    "\n",
    "def make_pair_dataset(images, labels):\n",
    "    digit_indices = [np.where(labels == i)[0] for i in range(CLASSES)]\n",
    "    pairs, y = create_pairs(images, digit_indices)\n",
    "    return pairs, y\n",
    "\n",
    "tr_pairs, tr_y = make_pair_dataset(train_images, Y_train)\n",
    "te_pairs, te_y = make_pair_dataset(test_images, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60a9fe7f-12fa-4678-a441-4104b0f2e5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(image, size):\n",
    "    scale_percent = size\n",
    "    width = int(image.shape[1] * scale_percent / 100)\n",
    "    height = int(image.shape[0] * scale_percent / 100)\n",
    "    dim = (width, height)\n",
    "    resized = cv2.resize(image, dim, interpolation = cv2.INTER_AREA)\n",
    "    display(Image.fromarray(resized))\n",
    "\n",
    "#show_image(X_train[30], 700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27368330-ce16-4309-aa49-58b1e0590925",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tr_y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_22064/1804045785.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtr_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtr_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mte_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mte_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mx_tra\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_tra\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_pairs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtr_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstratify\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtr_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m21\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tr_y' is not defined"
     ]
    }
   ],
   "source": [
    "tr_y = tr_y.astype(np.float32)\n",
    "te_y = te_y.astype(np.float32)\n",
    "\n",
    "x_tra, x_val, y_tra, y_val = train_test_split(tr_pairs, tr_y, test_size=0.2, stratify=tr_y, random_state=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bdd73c25-d728-4ad2-9f1d-9cf82252ce6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### One hot encoding for labels \n",
    "\n",
    "train_lab_categorical = tf.keras.utils.to_categorical(\n",
    "    Y_train, num_classes=10, dtype='uint8')\n",
    "\n",
    "test_lab_categorical = tf.keras.utils.to_categorical(\n",
    "    Y_test, num_classes=10, dtype='uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5d1cf059-ee75-4a48-a97e-358d10d2255d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data shape after the split:  (48000, 28, 28)\n",
      "new validation data shape:  (12000, 28, 28)\n",
      "validation labels shape:  (12000, 10)\n"
     ]
    }
   ],
   "source": [
    "### Train -test split \n",
    "\n",
    "from sklearn.model_selection import train_test_split \n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_train, train_lab_categorical, test_size=0.20, \n",
    "                                                            stratify=train_lab_categorical, \n",
    "                                                            random_state=40, shuffle = True)\n",
    "\n",
    "print (\"train data shape after the split: \", X_train.shape)\n",
    "print ('new validation data shape: ', X_test.shape)\n",
    "print (\"validation labels shape: \", Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8f0efc8b-8919-4399-bdab-cd98f493e37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_types = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "be65a79f-3ba3-407d-b266-70fb657296af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def res_identity(x, filters): \n",
    "    #renet block where dimension doesnot change.\n",
    "    #The skip connection is just simple identity conncection\n",
    "    #we will have 3 blocks and then input will be added\n",
    "\n",
    "    x_skip = x # this will be used for addition with the residual block \n",
    "    f1, f2 = filters\n",
    "\n",
    "    #first block \n",
    "    x = Conv1D(f1, kernel_size=1, strides=1, padding='valid', kernel_regularizer=l2(0.001))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(activations.relu)(x)\n",
    "\n",
    "    #second block # bottleneck (but size kept same with padding)\n",
    "    x = Conv1D(f1, kernel_size=3, strides=1, padding='same', kernel_regularizer=l2(0.001))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(activations.relu)(x)\n",
    "\n",
    "    # third block activation used after adding the input\n",
    "    x = Conv1D(f2, kernel_size=1, strides=1, padding='valid', kernel_regularizer=l2(0.001))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    # x = Activation(activations.relu)(x)\n",
    "\n",
    "    # add the input \n",
    "    x = Add()([x, x_skip])\n",
    "    x = Activation(activations.relu)(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "67b9b015-e63e-485f-b40c-b690a1caf86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def res_conv(x, s, filters):\n",
    "    '''\n",
    "    here the input size changes''' \n",
    "    x_skip = x\n",
    "    f1, f2 = filters\n",
    "\n",
    "    # first block\n",
    "    x = Conv1D(f1, kernel_size=1, strides=s, padding='valid', kernel_regularizer=l2(0.001))(x)\n",
    "    # when s = 2 then it is like downsizing the feature map\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(activations.relu)(x)\n",
    "\n",
    "    # second block\n",
    "    x = Conv1D(f1, kernel_size=3, strides=1, padding='same', kernel_regularizer=l2(0.001))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(activations.relu)(x)\n",
    "\n",
    "    #third block\n",
    "    x = Conv1D(f2, kernel_size=1, strides=1, padding='valid', kernel_regularizer=l2(0.001))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    # shortcut \n",
    "    x_skip = Conv1D(f2, kernel_size=1, strides=s, padding='valid', kernel_regularizer=l2(0.001))(x_skip)\n",
    "    x_skip = BatchNormalization()(x_skip)\n",
    "\n",
    "    # add \n",
    "    x = Add()([x, x_skip])\n",
    "    x = Activation(activations.relu)(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f6defb21-1eca-44fa-a7ef-2f7de56d94ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet50():\n",
    "\n",
    "    input_im = Input(shape=(X_train.shape[1], X_train.shape[2]))\n",
    "    x = ZeroPadding1D(padding=2)(input_im)\n",
    "\n",
    "    # 1st stage\n",
    "    # here we perform maxpooling, see the figure above\n",
    "\n",
    "    x = Conv1D(64, kernel_size=7, strides=2)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(activations.relu)(x)\n",
    "    x = MaxPooling1D(3, strides=2)(x)\n",
    "\n",
    "    #2nd stage \n",
    "    # frm here on only conv block and identity block, no pooling\n",
    "\n",
    "    x = res_conv(x, s=1, filters=(64, 256))\n",
    "    x = res_identity(x, filters=(64, 256))\n",
    "    x = res_identity(x, filters=(64, 256))\n",
    "\n",
    "    # 3rd stage\n",
    "\n",
    "    x = res_conv(x, s=2, filters=(128, 512))\n",
    "    x = res_identity(x, filters=(128, 512))\n",
    "    x = res_identity(x, filters=(128, 512))\n",
    "    x = res_identity(x, filters=(128, 512))\n",
    "\n",
    "    # 4th stage\n",
    "\n",
    "    x = res_conv(x, s=2, filters=(256, 1024))\n",
    "    x = res_identity(x, filters=(256, 1024))\n",
    "    x = res_identity(x, filters=(256, 1024))\n",
    "    x = res_identity(x, filters=(256, 1024))\n",
    "    x = res_identity(x, filters=(256, 1024))\n",
    "    x = res_identity(x, filters=(256, 1024))\n",
    "\n",
    "    # 5th stage\n",
    "\n",
    "    x = res_conv(x, s=2, filters=(512, 2048))\n",
    "    x = res_identity(x, filters=(512, 2048))\n",
    "    x = res_identity(x, filters=(512, 2048))\n",
    "\n",
    "    # ends with average pooling and dense connection\n",
    "\n",
    "    x = AveragePooling1D(2, padding='same')(x)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(len(class_types), activation='softmax', kernel_initializer='he_normal')(x)\n",
    "\n",
    "    # define the model \n",
    "\n",
    "    model = Model(inputs=input_im, outputs=x, name='Resnet50')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "78eb3662-1929-49a1-8405-8674a7e39d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define some Callbacks\n",
    "def lrdecay(epoch):\n",
    "    lr = 1e-3\n",
    "    if epoch > 180:\n",
    "        lr *= 0.5e-3\n",
    "    elif epoch > 160:\n",
    "        lr *= 1e-3\n",
    "    elif epoch > 120:\n",
    "        lr *= 1e-2\n",
    "    elif epoch > 80:\n",
    "        lr *= 1e-1\n",
    "    #print('Learning rate: ', lr)\n",
    "    return lr\n",
    "  # if epoch < 40:\n",
    "  #   return 0.01\n",
    "  # else:\n",
    "  #   return 0.01 * np.math.exp(0.03 * (40 - epoch))\n",
    "lrdecay = tf.keras.callbacks.LearningRateScheduler(lrdecay) # learning rate decay  \n",
    "\n",
    "\n",
    "def earlystop(mode):\n",
    "    if mode=='acc':\n",
    "        estop = tf.keras.callbacks.EarlyStopping(monitor='val_acc', patience=15, mode='max')\n",
    "    elif mode=='loss':\n",
    "        estop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=15, mode='min')\n",
    "    return estop    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "33d826e5-5a01-400e-be70-7e40291cd8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_model = ResNet50()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ab712bf1-d1e3-4aa0-bb37-8d8a3aa761a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#resnet50_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9db0d71a-2e29-4acb-839e-01549fed10f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Similarity_Model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " ImageA_Input (InputLayer)      [(None, 28, 28)]     0           []                               \n",
      "                                                                                                  \n",
      " ImageB_Input (InputLayer)      [(None, 28, 28)]     0           []                               \n",
      "                                                                                                  \n",
      " Resnet50 (Functional)          (None, 10)           16066506    ['ImageA_Input[0][0]',           \n",
      "                                                                  'ImageB_Input[0][0]']           \n",
      "                                                                                                  \n",
      " merge_features (Concatenate)   (None, 20)           0           ['Resnet50[0][0]',               \n",
      "                                                                  'Resnet50[1][0]']               \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 16)           336         ['merge_features[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_161 (Batch  (None, 16)          64          ['dense_6[0][0]']                \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_149 (Activation)    (None, 16)           0           ['batch_normalization_161[0][0]']\n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 4)            68          ['activation_149[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_162 (Batch  (None, 4)           16          ['dense_7[0][0]']                \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_150 (Activation)    (None, 4)            0           ['batch_normalization_162[0][0]']\n",
      "                                                                                                  \n",
      " dense_8 (Dense)                (None, 1)            5           ['activation_150[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 16,066,995\n",
      "Trainable params: 16,013,835\n",
      "Non-trainable params: 53,160\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import concatenate\n",
    "img_a_in = Input(shape = X_train.shape[1:], name = 'ImageA_Input')\n",
    "img_b_in = Input(shape = X_train.shape[1:], name = 'ImageB_Input')\n",
    "img_a_feat = feature_model(img_a_in)\n",
    "img_b_feat = feature_model(img_b_in)\n",
    "combined_features = concatenate([img_a_feat, img_b_feat], name =\n",
    "'merge_features')\n",
    "combined_features = Dense(16, activation = 'linear')(combined_features)\n",
    "combined_features = BatchNormalization()(combined_features)\n",
    "combined_features = Activation('relu')(combined_features)\n",
    "combined_features = Dense(4, activation = 'linear')(combined_features)\n",
    "combined_features = BatchNormalization()(combined_features)\n",
    "combined_features = Activation('relu')(combined_features)\n",
    "combined_features = Dense(1, activation = 'sigmoid')(combined_features)\n",
    "similarity_model = Model(inputs = [img_a_in, img_b_in], outputs =\n",
    "[combined_features], name = 'Similarity_Model')\n",
    "similarity_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5a366fff-ea2a-4396-b8a8-ee201ca837b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "331a25fe-5c1f-4842-a104-1df0ba66234a",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=0,\n",
    "    patience=3,\n",
    "    verbose=0,\n",
    "    mode='auto',\n",
    "    baseline=None,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "save_model = tf.keras.callbacks.ModelCheckpoint(\n",
    "    \"/content/drive/MyDrive/Classroom/similarity_model\",\n",
    "    monitor='val_loss',\n",
    "    verbose=0,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=False,\n",
    ")\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "                              patience=1, min_lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4c248fdd-9316-4c78-91bd-27ef1b01b1c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/17\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 28, 28) for input KerasTensor(type_spec=TensorSpec(shape=(None, 28, 28), dtype=tf.float32, name='ImageA_Input'), name='ImageA_Input', description=\"created by layer 'ImageA_Input'\"), but it was called on an input with incompatible shape (128, 28).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 28, 28) for input KerasTensor(type_spec=TensorSpec(shape=(None, 28, 28), dtype=tf.float32, name='ImageB_Input'), name='ImageB_Input', description=\"created by layer 'ImageB_Input'\"), but it was called on an input with incompatible shape (128, 28).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 28, 28) for input KerasTensor(type_spec=TensorSpec(shape=(None, 28, 28), dtype=tf.float32, name='input_3'), name='input_3', description=\"created by layer 'input_3'\"), but it was called on an input with incompatible shape (128, 28).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/home/sveta/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/sveta/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/sveta/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/sveta/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 859, in train_step\n        y_pred = self(x, training=True)\n    File \"/home/sveta/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/home/sveta/anaconda3/lib/python3.9/site-packages/keras/engine/input_spec.py\", line 214, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" '\n\n    ValueError: Exception encountered when calling layer \"Resnet50\" (type Functional).\n    \n    Input 0 of layer \"zero_padding1d_2\" is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: (128, 28)\n    \n    Call arguments received:\n      • inputs=tf.Tensor(shape=(128, 28), dtype=float32)\n      • training=True\n      • mask=None\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2128/4278123086.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mEPOCH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m17\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mBS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m history = similarity_model.fit([X_train[:,0], X_train[:, 1]], Y_train, epochs=EPOCH, batch_size=BS, \n\u001b[0m\u001b[1;32m      4\u001b[0m                     validation_data=([X_test[:, 0], X_test[:, 1]], Y_test), callbacks=[early_stopping, save_model, reduce_lr])\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1146\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1147\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1148\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/home/sveta/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/sveta/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/sveta/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/sveta/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 859, in train_step\n        y_pred = self(x, training=True)\n    File \"/home/sveta/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/home/sveta/anaconda3/lib/python3.9/site-packages/keras/engine/input_spec.py\", line 214, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" '\n\n    ValueError: Exception encountered when calling layer \"Resnet50\" (type Functional).\n    \n    Input 0 of layer \"zero_padding1d_2\" is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: (128, 28)\n    \n    Call arguments received:\n      • inputs=tf.Tensor(shape=(128, 28), dtype=float32)\n      • training=True\n      • mask=None\n"
     ]
    }
   ],
   "source": [
    "EPOCH = 17\n",
    "BS = 128\n",
    "history = similarity_model.fit([X_train[:,0], X_train[:, 1]], Y_train, epochs=EPOCH, batch_size=BS, \n",
    "                    validation_data=([X_test[:, 0], X_test[:, 1]], Y_test), callbacks=[early_stopping, save_model, reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974453d6-e64d-4e01-9a10-8e3f1630877b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
