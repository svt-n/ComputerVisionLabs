{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "74653d0c-237e-46ba-869b-584a872271e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, ZeroPadding1D, Flatten, BatchNormalization, AveragePooling1D, Dense, Activation, Add \n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import activations\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e8a985e1-650a-42cb-897d-8d4bd330ceb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "043c21bc-550a-43d1-9f02-4287fab2f9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_types = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "59ee36f5-e8d2-4174-bb9c-437189d45e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def res_identity(x, filters): \n",
    "    #renet block where dimension doesnot change.\n",
    "    #The skip connection is just simple identity conncection\n",
    "    #we will have 3 blocks and then input will be added\n",
    "\n",
    "    x_skip = x # this will be used for addition with the residual block \n",
    "    f1, f2 = filters\n",
    "\n",
    "    #first block \n",
    "    x = Conv1D(f1, kernel_size=1, strides=1, padding='valid', kernel_regularizer=l2(0.001))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(activations.relu)(x)\n",
    "\n",
    "    #second block # bottleneck (but size kept same with padding)\n",
    "    x = Conv1D(f1, kernel_size=3, strides=1, padding='same', kernel_regularizer=l2(0.001))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(activations.relu)(x)\n",
    "\n",
    "    # third block activation used after adding the input\n",
    "    x = Conv1D(f2, kernel_size=1, strides=1, padding='valid', kernel_regularizer=l2(0.001))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    # x = Activation(activations.relu)(x)\n",
    "\n",
    "    # add the input \n",
    "    x = Add()([x, x_skip])\n",
    "    x = Activation(activations.relu)(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "aeb729ac-659d-49b9-aa3c-e495eb0cf62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def res_conv(x, s, filters):\n",
    "    '''\n",
    "    here the input size changes''' \n",
    "    x_skip = x\n",
    "    f1, f2 = filters\n",
    "\n",
    "    # first block\n",
    "    x = Conv1D(f1, kernel_size=1, strides=s, padding='valid', kernel_regularizer=l2(0.001))(x)\n",
    "    # when s = 2 then it is like downsizing the feature map\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(activations.relu)(x)\n",
    "\n",
    "    # second block\n",
    "    x = Conv1D(f1, kernel_size=3, strides=1, padding='same', kernel_regularizer=l2(0.001))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(activations.relu)(x)\n",
    "\n",
    "    #third block\n",
    "    x = Conv1D(f2, kernel_size=1, strides=1, padding='valid', kernel_regularizer=l2(0.001))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    # shortcut \n",
    "    x_skip = Conv1D(f2, kernel_size=1, strides=s, padding='valid', kernel_regularizer=l2(0.001))(x_skip)\n",
    "    x_skip = BatchNormalization()(x_skip)\n",
    "\n",
    "    # add \n",
    "    x = Add()([x, x_skip])\n",
    "    x = Activation(activations.relu)(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "978e1ee9-9c2a-4170-a702-da16d23c3ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet50():\n",
    "\n",
    "    input_im = Input(shape=(train_images.shape[1], train_images.shape[2]))\n",
    "    x = ZeroPadding1D(padding=2)(input_im)\n",
    "\n",
    "    # 1st stage\n",
    "    # here we perform maxpooling, see the figure above\n",
    "\n",
    "    x = Conv1D(64, kernel_size=7, strides=2)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(activations.relu)(x)\n",
    "    x = MaxPooling1D(3, strides=2)(x)\n",
    "\n",
    "    #2nd stage \n",
    "    # frm here on only conv block and identity block, no pooling\n",
    "\n",
    "    x = res_conv(x, s=1, filters=(64, 256))\n",
    "    x = res_identity(x, filters=(64, 256))\n",
    "    x = res_identity(x, filters=(64, 256))\n",
    "\n",
    "    # 3rd stage\n",
    "\n",
    "    x = res_conv(x, s=2, filters=(128, 512))\n",
    "    x = res_identity(x, filters=(128, 512))\n",
    "    x = res_identity(x, filters=(128, 512))\n",
    "    x = res_identity(x, filters=(128, 512))\n",
    "\n",
    "    # 4th stage\n",
    "\n",
    "    x = res_conv(x, s=2, filters=(256, 1024))\n",
    "    x = res_identity(x, filters=(256, 1024))\n",
    "    x = res_identity(x, filters=(256, 1024))\n",
    "    x = res_identity(x, filters=(256, 1024))\n",
    "    x = res_identity(x, filters=(256, 1024))\n",
    "    x = res_identity(x, filters=(256, 1024))\n",
    "\n",
    "    # 5th stage\n",
    "\n",
    "    x = res_conv(x, s=2, filters=(512, 2048))\n",
    "    x = res_identity(x, filters=(512, 2048))\n",
    "    x = res_identity(x, filters=(512, 2048))\n",
    "\n",
    "    # ends with average pooling and dense connection\n",
    "\n",
    "    x = AveragePooling1D(2, padding='same')(x)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(len(class_types), activation='softmax', kernel_initializer='he_normal')(x)\n",
    "\n",
    "    # define the model \n",
    "\n",
    "    model = Model(inputs=input_im, outputs=x, name='Resnet50')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "073ac901-31e2-4151-8000-469335ee5654",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define some Callbacks\n",
    "def lrdecay(epoch):\n",
    "    lr = 1e-3\n",
    "    if epoch > 180:\n",
    "        lr *= 0.5e-3\n",
    "    elif epoch > 160:\n",
    "        lr *= 1e-3\n",
    "    elif epoch > 120:\n",
    "        lr *= 1e-2\n",
    "    elif epoch > 80:\n",
    "        lr *= 1e-1\n",
    "    #print('Learning rate: ', lr)\n",
    "    return lr\n",
    "  # if epoch < 40:\n",
    "  #   return 0.01\n",
    "  # else:\n",
    "  #   return 0.01 * np.math.exp(0.03 * (40 - epoch))\n",
    "lrdecay = tf.keras.callbacks.LearningRateScheduler(lrdecay) # learning rate decay  \n",
    "\n",
    "\n",
    "def earlystop(mode):\n",
    "    if mode=='acc':\n",
    "        estop = tf.keras.callbacks.EarlyStopping(monitor='val_acc', patience=15, mode='max')\n",
    "    elif mode=='loss':\n",
    "        estop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=15, mode='min')\n",
    "    return estop    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8eaf582b-a236-4676-b6dd-bc5d513d857b",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_model = ResNet50()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2d5b3e-fe9b-4e6f-9779-fbba035dc645",
   "metadata": {},
   "source": [
    "Siamese model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "138d6fd6-0cb1-4154-85a1-9da28dc3026c",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_shape =  np.concatenate((test_images.shape[1:], [1]))\n",
    "img_a_in = tf.keras.layers.Input(shape =img_shape, name = 'ImageA_Input')\n",
    "img_b_in = tf.keras.layers.Input(shape =img_shape, name = 'ImageB_Input')\n",
    "img_a_feat = feature_model(img_a_in)\n",
    "img_b_feat = feature_model(img_b_in)\n",
    "combined_features = tf.keras.layers.concatenate([img_a_feat, img_b_feat], name='merge_features')\n",
    "combined_features = tf.keras.layers.Dense(16, activation = 'linear')(combined_features)\n",
    "combined_features = tf.keras.layers.BatchNormalization()(combined_features)\n",
    "combined_features = tf.keras.layers.Activation('relu')(combined_features)\n",
    "combined_features = tf.keras.layers.Dense(4, activation = 'linear')(combined_features)\n",
    "combined_features = tf.keras.layers.BatchNormalization()(combined_features)\n",
    "combined_features = tf.keras.layers.Activation('relu')(combined_features)\n",
    "combined_features = tf.keras.layers.Dense(1, activation = 'sigmoid')(combined_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7a0cd037-8c0c-4113-aece-f03c16347eaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Similarity_Model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " ImageA_Input (InputLayer)      [(None, 28, 28, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " ImageB_Input (InputLayer)      [(None, 28, 28, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " Resnet50 (Functional)          (None, 10)           16066506    ['ImageA_Input[0][0]',           \n",
      "                                                                  'ImageB_Input[0][0]']           \n",
      "                                                                                                  \n",
      " merge_features (Concatenate)   (None, 20)           0           ['Resnet50[0][0]',               \n",
      "                                                                  'Resnet50[1][0]']               \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 16)           336         ['merge_features[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_161 (Batch  (None, 16)          64          ['dense_5[0][0]']                \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_149 (Activation)    (None, 16)           0           ['batch_normalization_161[0][0]']\n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 4)            68          ['activation_149[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_162 (Batch  (None, 4)           16          ['dense_6[0][0]']                \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_150 (Activation)    (None, 4)            0           ['batch_normalization_162[0][0]']\n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 1)            5           ['activation_150[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 16,066,995\n",
      "Trainable params: 16,013,835\n",
      "Non-trainable params: 53,160\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "similarity_model = tf.keras.Model(inputs = [img_a_in, img_b_in], outputs=[combined_features], name = 'Similarity_Model')\n",
    "similarity_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "681ca728-e0af-4f5b-9bfa-fe05ff20ef3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3b7de5b1-1bf8-4f0e-b97e-83399c5207eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=0,\n",
    "    patience=3,\n",
    "    verbose=0,\n",
    "    mode='auto',\n",
    "    baseline=None,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "save_model = tf.keras.callbacks.ModelCheckpoint(\n",
    "    \"/content/drive/MyDrive/Classroom/similarity_model\",\n",
    "    monitor='val_loss',\n",
    "    verbose=0,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=False,\n",
    ")\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "                              patience=1, min_lr=0.0001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e813bf7c-1d06-45ca-ad80-0fcd985af621",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_tra' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4502/3610878592.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m history = similarity_model.fit([x_tra[:,0], x_tra[:, 1]], y_tra, epochs=EPOCH, batch_size=BS, \n\u001b[0m\u001b[1;32m      2\u001b[0m                     validation_data=([x_val[:, 0], x_val[:, 1]], y_val), callbacks=[early_stopping, save_model, reduce_lr])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x_tra' is not defined"
     ]
    }
   ],
   "source": [
    "history = similarity_model.fit([x_tra[:,0], x_tra[:, 1]], y_tra, epochs=EPOCH, batch_size=BS, \n",
    "                    validation_data=([x_val[:, 0], x_val[:, 1]], y_val), callbacks=[early_stopping, save_model, reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f078ef-2076-4d60-94c4-51962d1dc50f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
